{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import itertools\n",
    "import collections\n",
    "import random\n",
    "import pulp\n",
    "import json\n",
    "import functools\n",
    "import time\n",
    "import random\n",
    "def timeit(method):\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()\n",
    "        print('%r %f sec' %(method.__name__, te-ts))\n",
    "        return result\n",
    "    return timed\n",
    "graph = {'A': {'children':['D'],'parents':[], 'node_w':4, 'edge_w':10},\n",
    "         'B': {'children':['E'],'parents':[], 'node_w':4, 'edge_w':10},\n",
    "         'C': {'children':['F'],'parents':[], 'node_w':4, 'edge_w':10},\n",
    "         'D': {'children':['G'],'parents':['A'], 'node_w':20, 'edge_w':2},\n",
    "         'E': {'children':['G'],'parents':['B'], 'node_w':20, 'edge_w':2},\n",
    "         'F': {'children':['G'],'parents':['C'], 'node_w':20, 'edge_w':2},\n",
    "         'G': {'children':['H'],'parents':['D','E','F'], 'node_w':30, 'edge_w':1},\n",
    "         'H': {'children':[],'parent':['G'], 'node_w':0, 'edge_w':0}}\n",
    "def create_processors(total_num):\n",
    "    def processor_power(num):\n",
    "        if num==0:\n",
    "            return 10**5\n",
    "        else:\n",
    "            return 2*num\n",
    "    return {i:processor_power(i) for i in range(total_num)}\n",
    "def create_rssi(total_num):\n",
    "    def to_others(total,i):\n",
    "        def rssi(i,j):\n",
    "            if i==j:\n",
    "                return 10**6\n",
    "            else:\n",
    "                return 10\n",
    "        return{j:rssi(i,j) for j in range(total)}\n",
    "    other_gen = functools.partial(to_others,total_num)\n",
    "    return{i:other_gen(i) for i in range(total_num)}\n",
    "processors = create_processors(30)\n",
    "rssi = create_rssi(30)\n",
    "constraints = {'A':range(0,30),\n",
    "               'B':range(0,30),\n",
    "               'C':range(0,30),\n",
    "               'D':range(0,30),\n",
    "               'E':range(0,30),\n",
    "               'F':range(0,30),\n",
    "               'G':range(30),\n",
    "               'H':[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_communication_power(a, b, rssi):\n",
    "    \"\"\"a and b are the names of processor\"\"\"\n",
    "    return rssi[a][b]\n",
    "def find_computation_power(a, processors):\n",
    "    return processors[a]\n",
    "def find_node_cost(node_k,node_v, assignment):\n",
    "    \"\"\"node is a key value pair, assignments is a named tuple\"\"\"\n",
    "    origin = node_k\n",
    "    destinations = node_v['children']\n",
    "    assigned_origin = getattr(assignment, origin)\n",
    "    assigned_destinations = [getattr(assignment, i) for i in destinations]\n",
    "    comp_cost = node_v['node_w']/processors[assigned_origin]\n",
    "    comm_cost_next = sum([node_v['edge_w']/rssi[assigned_origin][i] for i in assigned_destinations])\n",
    "    return comp_cost+comm_cost_next\n",
    "def find_total_cost(graph, assignment):\n",
    "    \"\"\"iterate through graph finding the assignment for each node\n",
    "    and summing the total cost of the graph for that assignment\"\"\"\n",
    "    total_cost = sum([find_node_cost(k,v, assignment) for k,v in graph.items()])\n",
    "    return total_cost\n",
    "def all_possible_assignments(graph, processors, constraints):\n",
    "    assignment_template = collections.namedtuple('Assignment', (' ').join(sorted([n for n in graph])))\n",
    "    keylist = graph.keys()\n",
    "    possible_values_bykey = [constraints[i] for i in sorted(keylist)]\n",
    "    all_combination_generator = itertools.product(*possible_values_bykey)\n",
    "    assignment_generator = (assignment_template(*i) for i in all_combination_generator)\n",
    "    return assignment_generator\n",
    "@timeit\n",
    "def optimise(graph, constraints):\n",
    "    q = asyncio.PriorityQueue(maxsize = 10)\n",
    "    gen = all_possible_assignments(graph, processors, constraints)\n",
    "    for a in gen:\n",
    "        cost = -1*find_total_cost(graph, a)\n",
    "        try:\n",
    "            q.put_nowait((cost, a))\n",
    "        except:\n",
    "            q.get_nowait()\n",
    "            q.put_nowait((cost,a))\n",
    "    return sorted(q._queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print('problem size: ', len(list(all_possible_assignments(graph, processors,constraints))))\n",
    "#q = optimise(graph, constraints)\n",
    "#print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dummy_namer(tupl):\n",
    "    template = collections.namedtuple('Assignment', 'edge parent child')\n",
    "    return template(edge=tupl[0], parent=tupl[1], child=tupl[2])\n",
    "def flattener(listoflists):\n",
    "    return list(itertools.chain(*listoflists))\n",
    "def lazy_flattener(listoflists):\n",
    "    return itertools.chain(*listoflists)\n",
    "def find_node_edges(nodekey,nodevalue):\n",
    "    return itertools.product(nodekey, nodevalue['children'])\n",
    "def find_graph_edges(graph):\n",
    "    \"\"\"given a dictionary representation of a graph\n",
    "    generate a list of the graph edges as tuples\"\"\"\n",
    "    nested_combinations = (find_node_edges(k,v) for k,v in graph.items())\n",
    "    return lazy_flattener(nested_combinations)\n",
    "def find_edgeparents(edge,constraints):\n",
    "    \"\"\"given an edge from graph, find valid parent processors given constraints\"\"\"\n",
    "    parent_node = edge[0]\n",
    "    return constraints[parent_node]\n",
    "def find_edgechildren(edge,constraints):\n",
    "    \"\"\"given an edge from graph, find valid parent processors given constraints\"\"\"\n",
    "    parent_node = edge[1]\n",
    "    return constraints[parent_node]\n",
    "def combination_finder(edge, constraints):\n",
    "    return ([edge], find_edgeparents(edge,constraints), find_edgechildren(edge,constraints))\n",
    "@timeit\n",
    "def timed_product(*args):\n",
    "    return itertools.product(*args)\n",
    "@timeit\n",
    "def unroll(combination_generator):\n",
    "    return (dummy_namer(comb) for product in combination_generator\n",
    "            for comb in product)\n",
    "@timeit\n",
    "def generate_dummies(graph, constraints):\n",
    "    \"\"\"generate a dummy variable named tuple for each\n",
    "    valid combination of edge, assigned parent, assigned child\"\"\"\n",
    "    edges = find_graph_edges(graph)\n",
    "    edge_possibilities = (combination_finder(edge,constraints) for edge in edges)\n",
    "    combination_generator = (timed_product(*edge) for edge in edge_possibilities)\n",
    "    all_dummies = unroll(combination_generator)\n",
    "    return all_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@timeit\n",
    "def add_cost_function(problem, dummy,dummy_vars, cost_calculator):\n",
    "    cost_function = (cost_calculator(i)*dummy_vars[i] for i in dummy)\n",
    "    problem += pulp.lpSum(cost_function), \"Sum of DAG edge weights\"\n",
    "    return problem\n",
    "def find_communication_power(a, b, rssi):\n",
    "    \"\"\"a and b are the names of processor\"\"\"\n",
    "    return rssi[a][b]\n",
    "def find_computation_power(a, processors):\n",
    "    return processors[a]\n",
    "def find_cost(graph, processors, rssi, a_dummy):\n",
    "    \"\"\"node is a key value pair, assignments is a named tuple\"\"\"\n",
    "    parent_node = graph[a_dummy.edge[0]]\n",
    "    child_node = graph[a_dummy.edge[1]]\n",
    "    parent = a_dummy.parent\n",
    "    child = a_dummy.child\n",
    "    comp_cost = parent_node['node_w']/processors[parent]\n",
    "    comm_cost_next = child_node['edge_w']/rssi[parent][child]\n",
    "    return comp_cost+comm_cost_next\n",
    "@timeit\n",
    "def edge_uniqueness(problem, dummies, dummy_vars):\n",
    "    \"\"\"given all possible dummy variable assignments\n",
    "    and the ILP problem, create the constraints that \n",
    "    guarantee only one dummy variable is turned on\n",
    "    for each edge\"\"\"\n",
    "    def get_edge(tupl):\n",
    "        return tupl.edge\n",
    "    grouped = (g for k,g in itertools.groupby(dummies, get_edge))\n",
    "    for group in grouped:\n",
    "        problem = constrain_one_edge(problem, group, dummy_vars)\n",
    "    return problem\n",
    "def constrain_one_edge(problem, grouped_by_edge, dummy_vars):\n",
    "    \"\"\"given a list of dummy variables corresponding to an edge\n",
    "    generate constraint statement for each edge e.g x+y+z <=1, -x-y-z <= 1\n",
    "    \"\"\"\n",
    "    edge_vars = (dummy_vars[i] for i in grouped_by_edge)\n",
    "    problem += (pulp.lpSum(edge_vars)==1,\n",
    "                \"sum of dummies eq 1 for: \"+str(random.random()))\n",
    "    return problem\n",
    "###=======make sure edge assignments match at nodes======###\n",
    "def match_parentchild(edge, edges):\n",
    "    \"\"\"find any neighbouring edges of node\"\"\"\n",
    "    return ((edge,i) for i in edges if i[0] == edge[1])\n",
    "def find_neighboring_edges(graph):\n",
    "    \"\"\"find all pairs of edges where child edge_i = parent edge_j\"\"\"\n",
    "    edges = find_graph_edges(graph)\n",
    "    return lazy_flattener((match_parentchild(edge, edges) for edge in edges))\n",
    "\n",
    "def inconsistent_with_one(in_edge_assignment, all_out_edges):\n",
    "    \"\"\"given an assignment corresponding to the edge into a given\n",
    "    node, find all assignments corresponding to the outward edge\n",
    "    where inward_child!=outward_parent\"\"\"\n",
    "    return ((in_edge_assignment,i) for i in all_out_edges\n",
    "            if i.parent!=in_edge_assignment.child)\n",
    "def edgepair_inconsistents(dummies, in_edge, out_edge):\n",
    "    \"\"\"given an in edge, e.g. ('A','D'), and an out edge, e.g.\n",
    "    ('D', 'G') find all dummy assignments pairs where\n",
    "    in_edge assignment child does not equals out_edge assignment parent\n",
    "    this is basically just the inconsistent_with_one function, but applied\n",
    "    to each possible assignment for the inward edge and then combined back\n",
    "    into a single list\n",
    "    \"\"\"\n",
    "    matching_in_edge = (i for i in dummies if i.edge == in_edge)\n",
    "    matching_out_edge = [i for i in dummies if i.edge == out_edge]\n",
    "    return lazy_flattener((inconsistent_with_one(i, matching_out_edge)\n",
    "                      for i in matching_in_edge))\n",
    "def all_inconsistents(graph, dummies):\n",
    "    \"\"\"this function applies the find_inconsistent_assignments function\n",
    "    over the whole graph: first by finding all pairs of in_edge, out_edge\n",
    "    and then simply applying the function to each of these pairs in turn\"\"\"\n",
    "    edge_pairs = find_neighboring_edges(graph)\n",
    "    catcher = functools.partial(edgepair_inconsistents, dummies)\n",
    "    wrong_nodes = lazy_flattener((catcher(*i) for i in edge_pairs))\n",
    "    return wrong_nodes\n",
    "@timeit\n",
    "def inout_consistency(graph, dummies, problem, dummy_vars):\n",
    "    all_matchers = all_inconsistents(graph, dummies)\n",
    "    for inconsistent_pair in all_matchers:\n",
    "        description = json.dumps(inconsistent_pair)\n",
    "        added_dummy_vars = [dummy_vars[i] for i in inconsistent_pair]\n",
    "        problem += (pulp.lpSum(added_dummy_vars)<=1,\n",
    "        \"pick one of mutex pair: \"+description)\n",
    "    return problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@timeit\n",
    "def create_list_from_gen(gen):\n",
    "    return list(gen)\n",
    "@timeit\n",
    "def formulate_LP(graph, constraints, processors, rssi):\n",
    "    d_gen = functools.partial(generate_dummies, graph, constraints)\n",
    "    d = create_list_from_gen(d_gen())\n",
    "    print('len d: ', len(d))\n",
    "    problem = pulp.LpProblem(\"DAG\",pulp.LpMinimize)\n",
    "    dummy_vars = pulp.LpVariable.dicts(\"Sensor\",d,0, 1, 'Binary')\n",
    "    cost_calculator = functools.partial(find_cost, graph, processors, rssi)\n",
    "    problem = add_cost_function(problem, d, dummy_vars, cost_calculator)\n",
    "    problem = edge_uniqueness(problem, d, dummy_vars)\n",
    "    problem = inout_consistency(graph, d_gen(), problem, dummy_vars)\n",
    "    return problem\n",
    "@timeit\n",
    "def solver(p):\n",
    "    return p.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'unroll' 0.000002 sec\n",
      "'generate_dummies' 0.000186 sec\n",
      "'timed_product' 0.000005 sec\n",
      "'timed_product' 0.000007 sec\n",
      "'timed_product' 0.000007 sec\n",
      "'timed_product' 0.000007 sec\n",
      "'timed_product' 0.000006 sec\n",
      "'timed_product' 0.000007 sec\n",
      "'timed_product' 0.000007 sec\n",
      "'create_list_from_gen' 5.903480 sec\n",
      "len d:  5430\n",
      "'add_cost_function' 0.443629 sec\n",
      "'edge_uniqueness' 0.097500 sec\n",
      "'unroll' 0.000002 sec\n",
      "'generate_dummies' 0.000046 sec\n",
      "'inout_consistency' 0.000040 sec\n",
      "'formulate_LP' 6.532563 sec\n",
      "False\n",
      "'solver' 0.266676 sec\n"
     ]
    }
   ],
   "source": [
    "p = formulate_LP(graph, constraints,processors, rssi)\n",
    "print(p==None)\n",
    "solved = solver(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal\n",
      "[[(\"Sensor_Assignment(edge=('A',_'D'),_parent=0,_child=0)\", 1.0)], [(\"Sensor_Assignment(edge=('B',_'E'),_parent=0,_child=0)\", 1.0)], [(\"Sensor_Assignment(edge=('C',_'F'),_parent=0,_child=0)\", 1.0)], [(\"Sensor_Assignment(edge=('D',_'G'),_parent=0,_child=0)\", 1.0)], [(\"Sensor_Assignment(edge=('E',_'G'),_parent=0,_child=0)\", 1.0)], [(\"Sensor_Assignment(edge=('F',_'G'),_parent=0,_child=0)\", 1.0)], [(\"Sensor_Assignment(edge=('G',_'H'),_parent=0,_child=0)\", 1.0)]]\n",
      "0.001029\n"
     ]
    }
   ],
   "source": [
    "cost_calculator = functools.partial(find_cost, graph, processors, rssi)\n",
    "print(pulp.LpStatus[p.status])\n",
    "all_nonzero = [(v.name,v.varValue) for v in p.variables() if v.varValue >0]\n",
    "def keyfunct(tupl):\n",
    "    return tupl[0].split(',_parent')[0]\n",
    "grouped = [list(g) for k,g in itertools.groupby(all_nonzero, keyfunct)]\n",
    "def get_val(tupl):\n",
    "    return tupl[1]\n",
    "chosen = [max(i, key = get_val) for i in grouped]\n",
    "print(grouped)\n",
    "print(pulp.value(p.objective))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e46184627ba1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = list(range(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "5000*0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
